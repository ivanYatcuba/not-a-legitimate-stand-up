{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T15:37:53.789742Z",
     "start_time": "2025-08-31T15:37:51.449104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "load_dotenv()"
   ],
   "id": "a39fda69e954fab5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-31T15:37:57.728467Z",
     "start_time": "2025-08-31T15:37:53.794282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "original_model_name = 'google/gemma-3-270m-it'\n",
    "\n",
    "new_model = AutoModelForCausalLM.from_pretrained(\n",
    "    '/home/ivan/git/not-a-legitimate-stand-up/train/joke-generator',\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=getattr(torch, 'float16'),\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    ),\n",
    "    attn_implementation='flash_attention_2',\n",
    "    device_map=\"cuda:0\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    original_model_name,\n",
    "    use_default_system_prompt=False,\n",
    "    device_map=new_model.device,\n",
    ")\n",
    "\n",
    "generation_params = GenerationConfig(\n",
    "    max_new_tokens=1024,\n",
    "    temperature=1.2,\n",
    "    top_k=25,\n",
    "    top_p=1,\n",
    "    repetition_penalty=1.1,\n",
    "    eos_token_id=[1, 107],\n",
    "    do_sample=True,\n",
    ")\n",
    "\n",
    "original_model = AutoModelForCausalLM.from_pretrained(\n",
    "    original_model_name,\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation='eager'\n",
    ").to(\"cuda:0\")"
   ],
   "id": "7ac81cfab5ea8021",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T15:40:04.560797Z",
     "start_time": "2025-08-31T15:40:02.168432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_ids = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\",\n",
    "                         \"text\": \"Output ONLY one short joke in Ukrainian language. Do NOT add other text.\"}, ]\n",
    "        },\n",
    "        {'role': \"user\", 'content': f'Розкажи жарт'}\n",
    "    ],\n",
    "    return_tensors='pt',\n",
    "    add_generation_prompt=True,\n",
    "    return_dict=True,\n",
    "    return_full_text=False,\n",
    ").to(new_model.device)\n",
    "outputs_orig = original_model.generate(**input_ids, generation_config=generation_params)\n",
    "outputs = new_model.generate(**input_ids, generation_config=generation_params)\n",
    "\n",
    "joke_orig = tokenizer.decode(outputs_orig[0])\n",
    "joke = tokenizer.decode(outputs[0])\n",
    "\n",
    "print(joke_orig)\n",
    "print('-------------')\n",
    "print(joke)"
   ],
   "id": "358728ee090f703e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><start_of_turn>user\n",
      "Output ONLY one short joke in Ukrainian language. Do NOT add other text.\n",
      "\n",
      "Розкажи жарт<end_of_turn>\n",
      "<start_of_turn>model\n",
      "Одяс у кулінарний майстермент, який збігує банку з великим обсягом товарів, а потім збирають на спеціальній фермі, яка робить з нього величезну ціну. На жаль, це все забагато коштує гроші!\n",
      "\n",
      "-------------\n",
      "<bos><start_of_turn>user\n",
      "Output ONLY one short joke in Ukrainian language. Do NOT add other text.\n",
      "\n",
      "Розкажи жарт<end_of_turn>\n",
      "<start_of_turn>model\n",
      "Жарт-жарт... Да як же, я так здею з ним не розбирався на бак, звичайно що не можехте! Говно слібається і мене в бак продимуєте на ножальну.</strong>\r\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
